{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4087 blocks loaded\n"
     ]
    }
   ],
   "source": [
    "# path of blocks\n",
    "SOURCE_PATH = '../data/txn_data'\n",
    "# SOURCE_PATH = 'testData'\n",
    "# read files \n",
    "block_list = os.listdir(SOURCE_PATH)\n",
    "sorted_block_list = [y for _, y in sorted([(int(a.split('.')[0]), a) for a in block_list])]\n",
    "sorted_block_list = sorted_block_list\n",
    "# print(sorted_block_list[:10])\n",
    "print(f\"There are {len(sorted_block_list)} blocks loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_block_txn_list(block_json_file: str) -> dict:\n",
    "    \"\"\"\n",
    "    @input: a block json file, e.g., 1111.json\n",
    "    @output: a list of transaction in that block\n",
    "    \"\"\"\n",
    "    json_path = os.path.join(SOURCE_PATH, block_json_file)\n",
    "    f = open(json_path)\n",
    "    json_data = json.load(f)\n",
    "    tx = json_data['tx']\n",
    "    f.close()\n",
    "    return tx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load two dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../heuristic_data/transaction_address_summary.json') as f:\n",
    "    transaction_address_summary = json.load(f)\n",
    "\n",
    "with open('../heuristic_data/two_output_address_summary.json') as f:\n",
    "    two_output_address_summary = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition transactons with 2 outputs into 4 categories:\n",
    "- Address reuse \n",
    "- Cluster member \n",
    "- Unknown change\n",
    "- Overlay Application\n",
    "\n",
    "## 2 Partition Functions\n",
    "- check_address_reuse\n",
    "- check_OP_RETURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDRESS_REUSE_CODE = 0\n",
    "CLUSTER_MEMBER_CODE = 1\n",
    "UNKNOWN_CHANGE_CODE = 2\n",
    "OVERLAY_APPLICATION_CODE = 3\n",
    "\n",
    "CLUSTERING_CANDIDATE = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_address_reuse(txn: dict) -> bool:\n",
    "    \"\"\"\n",
    "    @input: one single transaction, inputs list, outputs list\n",
    "    @output: address_reuse bit // if reuse exists, then 1, else 0 \n",
    "    \"\"\"\n",
    "    input_addresses = []\n",
    "\n",
    "    for input_ in txn[\"inputs\"]:\n",
    "        if \"prev_out\" in input_:\n",
    "            input_addresses.append(input_[\"prev_out\"][\"addr\"])\n",
    "\n",
    "    for output in txn[\"out\"]:\n",
    "        if \"addr\" not in output:\n",
    "            continue \n",
    "        if output[\"addr\"] in input_addresses:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_OP_RETURN(txn: dict) -> bool:\n",
    "    \"\"\"\n",
    "    @input: one single transaction, inputs list, outputs list\n",
    "    @ouput: True if the transaction is OP_RETURN, False otherwise \n",
    "    \"\"\"\n",
    "    for output in txn['out']:\n",
    "        if 'script' in output and output['script'].startswith('6a'):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4087/4087 [04:03<00:00, 16.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1,231,860 transactions with address reuse problem\n",
      "There are 16,165 transactions with overlay application problem\n",
      "There are 4,143,799 candidate transactions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ADDRESS_REUSE_COUNTER = 0\n",
    "CLUSTER_MEMBER_COUNTER = 0\n",
    "UNKNOWN_CHANGE_COUNTER = 0\n",
    "OVERLAY_APPLICATION_COUNTER = 0\n",
    "\n",
    "transaction_candidate_list = []\n",
    "\"\"\"store a list of (time, transactions) that are not \"reuse address\" and \"OP_RETURN\" \"\"\"\n",
    "\n",
    "for block_json_file in tqdm(sorted_block_list[:]):\n",
    "    # get transaction list of that block\n",
    "    txns_list = get_block_txn_list(block_json_file)\n",
    "\n",
    "    for txn in txns_list:\n",
    "        txn_hash = txn['hash']\n",
    "        # txn_time = txn['time']\n",
    "        if transaction_address_summary[txn_hash] != 2:\n",
    "            continue\n",
    "        try:\n",
    "            assert(txn_hash in two_output_address_summary)\n",
    "        except AssertionError:\n",
    "            print(txn_hash)\n",
    "            raise AssertionError(\"check the above transaction hash^\")\n",
    "        \n",
    "        \"\"\"case: check address reuse\"\"\"\n",
    "        if check_address_reuse(txn):\n",
    "            ADDRESS_REUSE_COUNTER += 1\n",
    "            two_output_address_summary[txn_hash] = ADDRESS_REUSE_CODE\n",
    "            continue\n",
    "            \n",
    "        \"\"\"check OP_RETURN \"\"\"\n",
    "        if check_OP_RETURN(txn): \n",
    "            OVERLAY_APPLICATION_COUNTER += 1\n",
    "            two_output_address_summary[txn_hash] = OVERLAY_APPLICATION_CODE\n",
    "            continue\n",
    "        \n",
    "        # transaction_candidate_list.append((txn_time, txn_hash))\n",
    "        transaction_candidate_list.append(txn_hash)\n",
    "\n",
    "\n",
    "print(f\"There are {ADDRESS_REUSE_COUNTER:,} transactions with address reuse problem\")\n",
    "print(f\"There are {OVERLAY_APPLICATION_COUNTER:,} transactions with overlay application problem\")\n",
    "print(f\"There are {len(transaction_candidate_list):,} candidate transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_reuse_transaction_address_list = []\n",
    "for i in two_output_address_summary:\n",
    "    if two_output_address_summary[i] == ADDRESS_REUSE_CODE:\n",
    "        address_reuse_transaction_address_list.append(i)\n",
    "\n",
    "with open('../heuristic_data/address_reuse_transaction_address_list.pkl', 'wb') as f:\n",
    "    pickle.dump(address_reuse_transaction_address_list, f)\n",
    "\n",
    "################################################################################################\n",
    "overlay_application_transaction_address_list = []\n",
    "for i in two_output_address_summary:\n",
    "    if two_output_address_summary[i] == OVERLAY_APPLICATION_CODE:\n",
    "        overlay_application_transaction_address_list.append(i)\n",
    "\n",
    "with open('../heuristic_data/overlay_application_transaction_address_list.pkl', 'wb') as f:\n",
    "    pickle.dump(overlay_application_transaction_address_list, f)\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "transaction_candidate_list = []\n",
    "for i in two_output_address_summary:\n",
    "    if two_output_address_summary[i] != OVERLAY_APPLICATION_CODE and two_output_address_summary[i] != ADDRESS_REUSE_CODE:\n",
    "        transaction_candidate_list.append(i)\n",
    "\n",
    "with open('../heuristic_data/transaction_candidate_list.pkl', 'wb') as f:\n",
    "    pickle.dump(transaction_candidate_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../heuristic_data/transaction_address_summary.json', 'w') as f:\n",
    "    json.dump(transaction_address_summary, f)\n",
    "\n",
    "with open('../heuristic_data/two_output_address_summary.json', 'w') as f:\n",
    "    json.dump(two_output_address_summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
