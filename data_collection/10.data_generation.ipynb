{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import pickle\n",
    "import scipy\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ground truth transaction: 86882\n"
     ]
    }
   ],
   "source": [
    "with open('../../heuristic_data/ground_truth_list.pkl', 'rb') as f:\n",
    "    ground_truth_list = pickle.load(f)\n",
    "print(f\"Number of ground truth transaction: {len(ground_truth_list)}\")\n",
    "txn_addr_list = ground_truth_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86882/86882 [00:00<00:00, 3214054.68it/s]\n"
     ]
    }
   ],
   "source": [
    "txn_addr_hash = {}\n",
    "for addr in tqdm(txn_addr_list):\n",
    "    txn_addr_hash[addr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4087 blocks loaded\n"
     ]
    }
   ],
   "source": [
    "# path of blocks\n",
    "SOURCE_PATH = '../../data/txn_data'\n",
    "# SOURCE_PATH = 'testData'\n",
    "# read files \n",
    "block_list = os.listdir(SOURCE_PATH)\n",
    "sorted_block_list = [y for _, y in sorted([(int(a.split('.')[0]), a) for a in block_list])]\n",
    "sorted_block_list = sorted_block_list\n",
    "# print(sorted_block_list[:10])\n",
    "print(f\"There are {len(sorted_block_list)} blocks loaded\")\n",
    "\n",
    "\n",
    "def get_block_txn_list(block_json_file: str) -> dict:\n",
    "    \"\"\"\n",
    "    @input: a block json file, e.g., 1111.json\n",
    "    @output: a list of transaction in that block\n",
    "    \"\"\"\n",
    "    json_path = os.path.join(SOURCE_PATH, block_json_file)\n",
    "    f = open(json_path)\n",
    "    json_data = json.load(f)\n",
    "    tx = json_data['tx']\n",
    "    f.close()\n",
    "    return tx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input and output addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "output_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4087/4087 [03:50<00:00, 17.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for block_json_file in tqdm(sorted_block_list[:]):\n",
    "    # get transaction list of that block\n",
    "    txns_list = get_block_txn_list(block_json_file)\n",
    "\n",
    "    for txn in txns_list:\n",
    "        txn_hash = txn['hash']\n",
    "        try: \n",
    "            flag = txn_addr_hash[txn_hash]\n",
    "            for input_ in txn['inputs']:\n",
    "                input_list.append(input_['prev_out']['addr'])\n",
    "            for output in txn['out']:\n",
    "                if \"addr\" in output:\n",
    "                    output_list.append(output['addr'])\n",
    "\n",
    "        except KeyError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1046340"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input_hash: 479887\n",
      "Length of output_hash: 135051\n",
      "Length of union_hash: 591629\n"
     ]
    }
   ],
   "source": [
    "input_hash = {}\n",
    "for input_idx, input_ in enumerate(list(set(input_list))):\n",
    "    input_hash[input_] = input_idx\n",
    "\n",
    "output_hash = {}\n",
    "for output_idx, output in enumerate(list(set(output_list))):\n",
    "    output_hash[output] = output_idx\n",
    "\n",
    "union_list = list(set(input_list).union(set(output_list)))\n",
    "\n",
    "union_hash = {}\n",
    "for idx, addr in enumerate(list(set(union_list))):\n",
    "    union_hash[addr] = idx\n",
    "\n",
    "\n",
    "print(f\"Length of input_hash: {len(input_hash)}\")\n",
    "print(f\"Length of output_hash: {len(output_hash)}\")\n",
    "print(f\"Length of union_hash: {len(union_hash)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../heuristic_data/input_hash.json\", \"w\") as f:\n",
    "    json.dump(input_hash, f)\n",
    "\n",
    "with open(\"../../heuristic_data/output_hash.json\", \"w\") as f:\n",
    "    json.dump(output_hash, f)\n",
    "\n",
    "with open(\"../../heuristic_data/union_hash.json\", \"w\") as f:\n",
    "    json.dump(union_hash, f)\n",
    "\n",
    "with open(\"../../heuristic_data/input_list.pkl\", \"w\") as f:\n",
    "    json.dump(list(input_hash), f)\n",
    "\n",
    "with open(\"../../heuristic_data/output_list.pkl\", \"w\") as f:\n",
    "    json.dump(list(output_hash), f)\n",
    "\n",
    "with open(\"../../heuristic_data/union_list.pkl\", \"w\") as f:\n",
    "    json.dump(list(union_hash), f)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 591,629 senders, there are 591,629 receivers\n"
     ]
    }
   ],
   "source": [
    "# data_matrix = dok_matrix((len(input_hash), len(output_hash)))\n",
    "# print(f\"There are {len(input_hash):,} senders, there are {len(output_hash):,} receivers\")\n",
    "\n",
    "\n",
    "data_matrix = dok_matrix((len(union_hash), len(union_hash)))\n",
    "print(f\"There are {data_matrix.shape[0]:,} senders, there are {data_matrix.shape[1]:,} receivers\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the data matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4087/4087 [05:11<00:00, 13.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for block_json_file in tqdm(sorted_block_list[:]):\n",
    "    # get transaction list of that block\n",
    "    txns_list = get_block_txn_list(block_json_file)\n",
    "\n",
    "    for txn in txns_list:\n",
    "        txn_hash = txn['hash']\n",
    "        try: \n",
    "            flag = txn_addr_hash[txn_hash]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        # put weight in each of the output\n",
    "        receiver_list = []\n",
    "        money_received_list = []\n",
    "        for output in txn['out']:\n",
    "            if \"addr\" in output and \"value\" in output:\n",
    "                receiver_list.append(output['addr'])\n",
    "                money_received_list.append(output['value'])\n",
    "\n",
    "        money_received_weight_list = [x / sum(money_received_list) \\\n",
    "                                            for x in money_received_list]\n",
    "        \n",
    "        for input_ in txn['inputs']:\n",
    "            input_value = input_['prev_out']['value']\n",
    "            money_distributed = [x * input_value for x in money_received_weight_list]\n",
    "            addr_sender = input_['prev_out']['addr']\n",
    "\n",
    "            for id, amount in enumerate(money_distributed):\n",
    "                addr_receiver = receiver_list[id]\n",
    "                data_matrix[union_hash[addr_sender], union_hash[addr_receiver]] += amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data matrix: 591,629, 591,629\n",
      "There are 350,024,873,641 entries in the data matrix\n",
      "There are 1,302,804 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of the data matrix: {data_matrix.shape[0]:,}, {data_matrix.shape[1]:,}\")\n",
    "print(f\"There are {data_matrix.shape[0] * data_matrix.shape[1]:,} entries in the data matrix\")\n",
    "print(f\"There are {data_matrix.count_nonzero():,} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data matrix: (591629, 591629)\n",
      "There are 350,024,873,641 entries in the data matrix\n",
      "There are 1,302,804 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of the data matrix: {data_matrix.shape}\")\n",
    "print(f\"There are {data_matrix.shape[0] * data_matrix.shape[1]:,} entries in the data matrix\")\n",
    "print(f\"There are {data_matrix.count_nonzero():,} non-zero entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591629, 591629)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix_coo = data_matrix.tocoo()\n",
    "scipy.sparse.save_npz('../../heuristic_data/data_matrix_square_coo.npz', data_matrix_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
